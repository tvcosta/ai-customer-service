# =============================================================================
# AI Customer Service - Environment Variables
# =============================================================================
# Copy this file to .env and adjust values for your environment.
# Docker Compose uses different defaults (see docker-compose.yml).
# The values below are for local development outside Docker.

# -----------------------------------------------------------------------------
# Backend Core (Python)
# -----------------------------------------------------------------------------

# Ollama LLM provider
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# Database (SQLite)
# Docker uses: sqlite+aiosqlite:///data/db/core.db
DATABASE_URL=sqlite+aiosqlite:///data/db/core.db

# OpenTelemetry
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317
OTEL_SERVICE_NAME=ai-customer-service-core

# Server binding
CORE_HOST=0.0.0.0
CORE_PORT=8000

# -----------------------------------------------------------------------------
# Backend API (.NET)
# -----------------------------------------------------------------------------

# Core API connection
CoreApi__BaseUrl=http://localhost:8000
CoreApi__TimeoutSeconds=30

# .NET listener URL
ASPNETCORE_URLS=http://localhost:5000

# OpenTelemetry (uses same OTEL_EXPORTER_OTLP_ENDPOINT as Core)
# Override OTEL_SERVICE_NAME for the API service:
# OTEL_SERVICE_NAME=ai-customer-service-api

# -----------------------------------------------------------------------------
# Frontend Admin (Next.js)
# -----------------------------------------------------------------------------

# Backend API URL (must be accessible from the browser)
NEXT_PUBLIC_API_URL=http://localhost:5000

# -----------------------------------------------------------------------------
# Grafana (observability dashboard)
# -----------------------------------------------------------------------------

GF_AUTH_ANONYMOUS_ENABLED=true
GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
